{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#D60B0B' size=5><center>__Тестовое задание в лабораторию интеллектуального транспорта__</center></font>\n",
    "_<font color='#D60B0B' size=3><center>Исполнитель: Зарубин В. В.</center></font>_\n",
    "***\n",
    "***\n",
    "__<font color='#D60B0B' size=3><center>Необходимо прогнать ячейки: Cell -> Run All Below</center></font>__\n",
    "\n",
    "\n",
    "__<font color='#D60B0B'><center>*Еще важно заметить,*</center></font>\n",
    "<font><center>что эта страница создавалась следуя хронологии моего погружения в тему.__</font></center>\n",
    "\n",
    "<font><center>__Чтобы посмотреть на выполнение *самого задания* необходимо перейти к секции [Результаты](#Результаты).__</font></center>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "### <font color='#D60B0B'>Источники</font>\n",
    "> От \"заказчика\"\n",
    "- __[Статья из дока: RTAB-Map as an Open-Source Lidar and Visual SLAM Library for Large-Scale and Long-Term Online Operation](https://introlab.3it.usherbrooke.ca/mediawiki-introlab/images/7/7a/Labbe18JFR_preprint.pdf)__\n",
    "- __[Real-Time Appearance-Based Mapping](http://introlab.github.io/rtabmap/)__\n",
    "- __[RTAB-Map on github, C++](https://github.com/introlab/rtabmap)__\n",
    "- __[RTAB-Map under ROS](http://wiki.ros.org/rtabmap)__\n",
    "\n",
    "> Далее, наверное, со всем можно сразу познакомиться на хабре\n",
    "- __[Обзор алгоритмов SLAM для камер глубины в ROS](https://habr.com/ru/post/373707/)__\n",
    "- __[Доклады второго ROS Meetup по навигации роботов](https://habr.com/ru/post/493792/)__\n",
    "- __[ROS: использование камер глубины](https://habr.com/ru/post/404757/)__\n",
    "\n",
    "> У Захаркина дожны быть отправные точки для зрения\n",
    "- __[CV 1](https://habr.com/ru/company/mipt/blog/450732/)__\n",
    "- __[CV 2](https://habr.com/ru/company/mipt/blog/458190/)__\n",
    "\n",
    "> Кажется, это старая статья про \"основы\". Под вопросом\n",
    "- __[Первые шаги вместе с ROS](https://habr.com/ru/company/tod/blog/204250/)__\n",
    "\n",
    "> Беспилотники\n",
    "- __[Автопилот своими силами](https://habr.com/ru/post/325704/)__\n",
    "\n",
    "> Дальше что то невнятное пока\n",
    "- __[Lyft 3D](https://habr.com/ru/post/467405/). На каггле подглядеть.__\n",
    "- __~~[Работа с несколькими моделями в Keras](https://habr.com/ru/post/465093/)~~. Вообще keras то зачем, но статью сохраню.__\n",
    "\n",
    "По ходу пунктов ТЗ, есть еще ссылки, наверное, чтобы я точно смог выполнить бэйзлайн. Или студентам даже на этапе теста активно помогают. Я привык к меньшему уровню наставничества, круто )  \n",
    "\n",
    "Пока что, идем по литературе, вникаем в тему. После на гит.\n",
    "\n",
    "У openAI вроде было много про RL, можно глянуть только после основы. Хотя зачем.\n",
    "\n",
    "Статью и плюсы на сладкое.\n",
    "\n",
    "Но не то чтобы, совсем, а то, возможно я сейчас буду читать что попало не по теме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.gifer.com/WDV.gif' style='width: 100px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем разбор материала. После быстрого экскурса гитхаба идет установка, а после непоняток и статья.\n",
    "\n",
    "На самом деле статья это скорее мануал по ros'у, одометрии, используемым алгоритмам, их разбор, RTABmap, как основа.\n",
    "\n",
    "### <font color='#D60B0B'>Установка ROS и RTABMAP</font>\n",
    "\n",
    "Находим возможность подтянуть rtabmap через докер.\n",
    "<img src='../media/rtabmap_dock.png' style='width: 600px'>\n",
    "\n",
    "К сожалению, на clear не вышло удобно собрать docker img, снова проблемы с \"доп\" видеокартой nvidia.\n",
    "\n",
    "Однажды попытка использовать nvidia для gpu ускорения нейронок на clear linux мне стоило недели жизни, некоторых \n",
    "\n",
    "файлов и 2-х крашей винды, причем один без возможности восстановления.\n",
    "<img src='../media/nvidia.png' style='width: 600px'>\n",
    "\n",
    "Так что вынужденным образом собираем по частям на ubuntu. Топорно через apt + cmake. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .output {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            text-align: right;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8cd2254e4a4f1991c4ed94981c2748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='tools:', options=('--', 'ros', 'rosdep', 'gazebo', 'rtabmap'), value='--')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run installed_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#D60B0B'>Запуск примеров из коробки</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d5fad99c1646b8b9cbe8edf8e852db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(button_style='danger', icons=('check', 'check'), options=('Улица', 'Помещение'), tooltips=(\"I'm …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "__Outdoor__\n",
       "<img src='../media/outdoor_1.png' style='width: 600px'>\n",
       "<table><tr><td><img src='../media/outdoor_2.png' style='width: 300px'><td><td>\n",
       "<img src='../media/outdoor_3.png' style='width: 300px'><td><tr><table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run bag_services.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, я умею крутить кино. На самом деле пока это какой то \"фит-предикт\", надо бы что то явно поинтереснее.\n",
    "    \n",
    "Между прочим, по CV пока ничего не понятно, возможно стоит посмотреть, что там вообще за данные.\n",
    "\n",
    "Следующий этап - изучаем туториалы, кандидат для изучения: [the Construct](https://www.theconstructsim.com/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.gifer.com/WDV.gif' style='width: 100px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#D60B0B'>Освоение ROS</font>\n",
    "\n",
    "На самом деле в задании не очень много, а тема занятная. Вдобавок - вот что мы видим в __/share__:\n",
    "\n",
    "<img src='../media/ros_share.png' style='width: 600px'>\n",
    "\n",
    "А вот и все звери:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5771e942c442f9a24dd471bfa1634f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Показать все', style=ButtonStyle(), tooltip=\"I'm waiting\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run show_share.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крайне интересно, но ничего не понятно. Так я прошелся по документации и туториалам.\n",
    "\n",
    "Таким образом, на этом этапе я немного расширил свой кругозор. Пересмотрел [источники](#Источники)  (я ж не был в теме тогда).\n",
    "\n",
    "> __Приведу здесь материалы, которые было полезно освоить. Пока что никакого map'a.__\n",
    "1. Курс ROS in 5 days от robot ignite [на С++](https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/ros-courses-ros-basics-in-5-days-c/) и [на python](https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/ros-python-course/)\n",
    "2. Его старая версия - [гуглдок](https://docs.google.com/document/d/1qyxLRca5o0URCggOBt0i32CU8aDuOKr9LcjkfZ7vRE0/edit#) с относительно коротким, но подробным описанием и [гитхаб](https://github.com/eborghi10/ROS-in-Five-Days) \n",
    "3. [Туториал с ros'a по catkin](http://wiki.ros.org/catkin/Tutorials) (скорее по ros package)\n",
    "4. [Кирпич по ROS](http://motorboard.ru/files/Learning-ROS-for-Robotics-Programming.pdf) \n",
    "\n",
    "Congratulations! You’re on the path to becoming a ROS Developer. __Теперь более подробно:__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        .output {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            text-align: right;\n",
       "        }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb2156ee77f4eb287a071c97f04e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Пункт ↑:', options=('--', '1', '2', '3', '4'), value='--')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ros_knowledge.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***    \n",
    "Теперь самое время все осмыслить и записать в подкорку)\n",
    "\n",
    "Далее ожидается сборка проекта и упаковка на гитхаб, так, чтобы бы можно было использовать, что я там напридумываю китайским методом.\n",
    "\n",
    "Однажды займусь и сламом.\n",
    "    \n",
    "<img src='https://brainconnection.brainhq.com/testlets/abc-gulp/images/_preloader.gif' style='width: 250px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так уж выходит, что на python можно сделать очень много. И это тенденция.\n",
    "\n",
    "Ясно, что ros работает c C++ и еще с python (вроде бы еще некий groovy). Но цитируя не помню кого:\n",
    "\n",
    "\"С++ это сборник эффективного кода для всего, что вам может понадобиться, но скорее всего того, что не понадобится. Если бы вы выкидывали из плюсов все ненужное, стараясь оставить крутые вещи, я уверен - вы бы пришли к python\".\n",
    "\n",
    "Поэтому я пришел к..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3abcffc2d74affa1c8d88300e6f5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='К чему?', style=ButtonStyle(), tooltip=\"I'm waiting\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run genius.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#D60B0B'>Неудачи и проблемы</font>\n",
    "Я отнесся к словам о ценности умения использовать различные инструменты для задачи вполне серьезно.\n",
    "\n",
    "Вдобавок сами пункты задания казалось были почти сделаны. Поэтому я и стал заниматься тем, что хорошо описывается картинкой сверху.\n",
    "\n",
    "__К _1 июля_ у меня уже было все, что есть сверху. Что же описано в этой секции заняло у меня время до _6 июля_.__\n",
    "\n",
    "Единственный плюс - я много раз сделал все заново и, надеюсь, лучше понял тему в целом. А также стал больше фиксировать, что я делаю.\n",
    "\n",
    "__По итогу я вернулся к слэму и нашел уже по картинке в голове отличную [статью](https://www.researchgate.net/publication/326986124_REAL-TIME_2D_AND_3D_SLAM_USING_RTAB-MAP_GMAPPING_AND_CARTOGRAPHER_PACKAGES) на researchgate.__ \n",
    "\n",
    "Весь процесс можно описать так:\n",
    "    \n",
    "                                    собрались ->  подготовились -> облажались "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12daf0f2c962486dab3f7ca2f6f2706a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(button_style='danger', icons=('check', 'check'), options=('Желаемое', 'Действительное'), tooltip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/IPython/core/display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"720\" height=\"480\" src=\"https://www.youtube.com/embed/EOdA5X-K8H8\" frameborder=\"1\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run comparison.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE!\n",
    "сделай скрины для сборки cart и что то из hamstir\n",
    "\n",
    "здесь должна быть кнопка\n",
    "\n",
    "результаты на \"до\" работку\n",
    "\n",
    "подписывай рисунки в результатах как в дипломе\n",
    "\n",
    "запись в peek оглавление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Далее скрытая секция, где я опишу кое-что из этих неудач и общий путь.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Во-первых__, я решил, пока есть время, поискать реализованные проекты симуляций со сборкой под ros.\n",
    "\n",
    "__Во-вторых__, я увидел возможность использовать обучение для планирования пути, все можно было писать лучше знакомыми .py скриптами.\n",
    "\n",
    "__В-третьих__, искал дополнительные инструменты для картирования. SLAM.\n",
    "\n",
    "Из просмотренного материала попробовал интегрировать следующее:\n",
    "1. [robot_training](https://github.com/Derek-TH-Wang/robot_training). Использование симуляций разных роботов и gym для демо демонстраций RL обучения. Используется, например, [fetch_tc](https://bitbucket.org/theconstructcore/fetch_tc/src/melodic-gazebo9/)\n",
    "\n",
    "\n",
    "2. [hamstir_gym](https://github.com/abefetterman/hamstir-gym). Продолжая тему openAI gym. Уже большой проект. RL для робота с моно камерой в помещении (симуляция).\n",
    "\n",
    "\n",
    "3. [cartographer](https://google-cartographer-ros.readthedocs.io/en/latest/). \"Реал-тайм\" построение 2D и 3D карт по информации с ros_msgs, .urdf файлов конфигурации робота. Работает по лазерной навигации. Подписки на топики можно контролировать с помощью .lua файлов конфигурации. В остальном - интерфейс ros.\n",
    "\n",
    "[__robot_training__](https://github.com/Derek-TH-Wang/robot_training)\n",
    "\n",
    "Были попытки запустить тестовые симуляции. Думаю, я не достаточно хорошо понимал, как работает обмен между процессами, что вообще стоит за кодом. Да и даже как нормально собрать проект.\n",
    "\n",
    "Как выглядел src для catkin:\n",
    "<img src='../media/src_robot_training.png' style='width: 600px'>\n",
    "\n",
    "Получил, что получил и занялся следующим ресурсом.\n",
    "<table><tr><td><img src='../media/fetch_gazebo_simulation.png' style='width: 500px'><td><td><img src='../media/fetch_tc_tries_calibrate_launch.png' style='width: 500px'><td><tr><table>\n",
    "\n",
    "[__hamstir_gym__](https://github.com/abefetterman/hamstir-gym)\n",
    "    \n",
    "В данном случае проект выглядит очень привлекательно. Сообщается, что он не готов, тем не менее видим следующие демонстрации:\n",
    "    \n",
    "<table><tr><td><img src='https://github.com/abefetterman/hamstir-gym/raw/master/images/train_demo.gif' style='width: 500px'><td><td><img src='https://github.com/abefetterman/hamstir-gym/raw/master/images/room6x6.png' style='width: 500px'><td><tr><table>\n",
    "\n",
    "Активно используются:\n",
    "- [stable_baselines](https://pypi.org/project/stable-baselines/)\n",
    "- [pybullet](https://pypi.org/project/pybullet/)\n",
    "- [Gibson environment](https://github.com/StanfordVL/GibsonEnv)\n",
    "    \n",
    "Также нужны стандартные вещи вроде gym, tf, torch, related deps.\n",
    "    \n",
    "Интересна папка examples.\n",
    "<img src='../media/hamstir_examples.png' style='width: 600px'>\n",
    "    \n",
    "    \n",
    "- Сразу сталкиваемся с проблемой совместимости с python2.7. Также для гибсона требуется RAM графики больше 6 Гб, но этим я почему то поинтересовался уже в конце. Были и другие проблемы, обычно чего то не хватало, не те версии, ее были прокинуты пути и т. д.\n",
    "    \n",
    "Собрал среду под третий питон, в том числе зачем то и ros. Предполагал как то соединить.\n",
    "<table><tr><td><img src='../media/facing_python_incompatability_catkin.png' style='width: 500px'><td><td><img src='../media/catkin_made_python3.png' style='width: 500px'><td><tr><tr><td><img src='../media/removing_python3_rospkg.png' style='width: 500px'><td><td><img src='../media/python3_ros.png' style='width: 500px'><td><tr><table>\n",
    "    \n",
    "- Долго возился с пониманием работы stable_baselines. Кажется, это местный движок для RL. Кое-что понял, но почти уверен, что продвинулся только чуть.    \n",
    "<table><tr><td><img src='../media/stable_baselines.png' style='width: 500px'><td><td><img src='../media/baselines_common.png' style='width: 500px'><td><tr><table>\n",
    "    \n",
    "\n",
    "- Что касается среды.\n",
    "    \n",
    "По причине не очень хорошего понимания пару раз случилась большая установка-переустановка.\n",
    "    \n",
    "    autoremove 150 пакетов\n",
    "<img src='../media/great_install_autoremove.png' style='width: 600px'>\n",
    "    \n",
    "Как итог после всего этого - __пришлось заново ставить ros и rtabmap__, поскольку он теперь неправильно работал, зато теперь я запомнил процесс. Приведу в конце секции.  \n",
    "    \n",
    "В общем был сделан разумный вывод, что с этим я не справлюсь.\n",
    "    \n",
    "Вспомнил, что мне нужно заниматься bag файлами, а не симуляциями в gazebo.\n",
    "\n",
    "    \n",
    "[__cartographer_ros__](https://google-cartographer-ros.readthedocs.io/en/latest/)\n",
    "    \n",
    "С cartographer_ros не то чтобы явная неудача, но повозиться пришлось, а в итоге большого смысла не имело, поскольку rtabmap располагает похожим функционалом.\n",
    "\n",
    "<img src='../media/map2_enhanced.gif' style='width: 600px'>\n",
    "\n",
    "Тем не менее, конечно есть свои плюсы. Описано в той же [статье 2D AND 3D SLAM USING RTAB-MAP GMAPPING AND CARTOGRAPHER](https://www.researchgate.net/publication/326986124_REAL-TIME_2D_AND_3D_SLAM_USING_RTAB-MAP_GMAPPING_AND_CARTOGRAPHER_PACKAGES).\n",
    "\n",
    "Как я уже писал, были неявные ошибки билдов и, следовательно, работы. Когда и что я сломал было уже совсем не понятно. Что то странное было с rosdep. Не находил модуль rosdistro при запуске sudo, и однажды приходилось собирать \"from source\". Не прокатило. \n",
    "\n",
    "<img src='../media/rtabmab_cant_read_topics.png' style='width: 600px'>\n",
    "\n",
    "В итоге, разобравшись поболее с работой catkin, билд был наконец успешно совершен. Поставлены rtabmap и cartographer - как раз для манипуляций с записями.\n",
    "\n",
    "__тесты__\n",
    "<img src='../media/ninja_test.png' style='width: 600px'>\n",
    "    \n",
    "__subscribe materials__\n",
    "<img src='../media/subscribe_understanding.png' style='width: 600px'>\n",
    "\n",
    "Дает понимание, с каких сенсоров приходят данные и что включать в скрипт.\n",
    "\n",
    "__демо картирования музея__\n",
    "<table><tr><td><img src='../media/cartographer_deutsches_museum.png' style='width: 500px'><td><td><img src='../media/another_museum.png' style='width: 500px'><td><tr><table>\n",
    "\n",
    "\n",
    "- Были и прочие проблемы, кажется я и так много написал. Оставлю напоследок свои \"журналы\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e49bcb7ffb4823b0dc1115075144d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Пара .txt', options=('--', 'Заметки часть 1', 'Заметки часть 2'), value='--')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run show_installment_txts.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#D60B0B'>Как правильно собирать проект</font>\n",
    "\n",
    "__ros-melodic__\n",
    "<img src='../media/great_install_full_except_rtabmap_rviz__learning_now_discarded.png' style='width: 600px'>\n",
    "\n",
    "__rtab-map__\n",
    "<img src='../media/rtabmap_install.png' style='width: 600px'>\n",
    "\n",
    "\n",
    "__opencv__ (manual cmake)\n",
    "<img src='../media/opencv_build.png' style='width: 600px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.gifer.com/WDV.gif' style='width: 100px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#D60B0B'>Результаты</font>\n",
    "\n",
    "__transform граф (одометрия)__\n",
    "<img src='../media/outdoor_tf.png' style='width: 900px; height: 500px'>\n",
    "\n",
    "__матрица поз робота__ (стерео, без оптимизации карты, просто 1 пример для картинки)\n",
    "<img src='../media/robot_poses_outdoor_nop.png' style='width: 600px'>\n",
    "\n",
    "__стерео карта анимация__\n",
    "<img src='../media/outdoor_mapping.gif' style='width: 600px'>\n",
    "\n",
    "***\n",
    "\n",
    "Визуальная одометрия здесь получается методом __F2F__ (frame to frame). Красные вспышки экрана говорят о большой ошибке в одометрии модели окружения и картинки с камер в подходе __Key-frame-based optimization__. То есть на гифке как раз был зафиксирован __loop closure__ при возвращении робота на позицию. Желтые имеют меньшее значение. При достоверном определении сенсорами позиций точек окружения (landmarks) согласно алгоритму key-frame \"избранные\" кадры с камер записываются в short term memory, затем обрабатываются и в long term memory и строится __оптимизированная карта реальной среды__. При обнаружении существенных расхождений и детекции loop closure карта положение робота корректируется. И карта также может быть скорректирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab0de7f72324e69a836efcc84bb0ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=8.0, continuous_update=False, description='Балл:', max=10.0, step=0.5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run estimate_me.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Новое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../media/slam_approaches.png'>\n",
    "<img src='../media/sensor_rtansfer_results.png'>\n",
    "<img src='../media/KF&F2F.png'>\n",
    "<img src='../media/icp_odom_motion.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__После синхронизации датчиков модуль краткосрочной памяти (STM) создает узел, запоминающий позу одометра, исходные данные датчика и дополнительную информацию, полезную для следующих модулей (например, визуальные слова для замыкания петли и обнаружения близости, а также локальную сетку занятости для сборки Глобальной карты).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СРАВНЕНИЕ ФОТО РГБ, ГЛУБИНЫ И\n",
    "RGB может быть использована как маска (качество) для глубины\n",
    "opencv используется для детекции фич потока изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__оптимизация графика распространяет вычисленную ошибку на весь график, чтобы уменьшить дрейф одометрии. С оптимизацией thegraph выходы OctoMap, облака точек и 2D-сетки занятости могут быть собраны и опубликованы во внешних модулях. когда проприоцептивная одометрия еще не доступна на роботе или когда она недостаточно точна, необходимо использовать визуальную или лидарную одометрию.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LIDAR\n",
    "если частота вращения лазерного сканера высока по сравнению со скоростью робота, лазерное сканирование будет иметь очень низкие искажения движения, и поэтому коррекция может быть проигнорирована без значительной потери точности регистрации.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Motion Prediction\n",
    "Проблема с этой техникой заключается в том, что если окружающая среда недостаточно сложна (например, в коридоре), одометрия может дрейфовать много, если нет ограничений на направление робота. a robot with a short-range lidar moving in a long corridor in which there are no doors (i.e.,not distinguishable geometry) would only see two parallel lines.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pose Update: After successful registration, odometry pose is then updated.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Key Frame and Point Cloud Map Update:  I\n",
    "Если отношение соответствия находится ниже фиксированного порога \"Odom/ScanKeyFrameThr\", то новый кадр становится ключевым кадром для S2S. для S2M перед интеграцией нового облака точек в карту облака точек выполняется экстрастеп. Карта вычитается из нового облака точек__\n",
    "\n",
    "__а потом ...\n",
    "оставшиеся точки добавляются на карту облака точек. Когда карта облака точек достигает фиксированного максимального порога \"OdomF2M/ScanMaxSize\", самые старые точки удаляются__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__БЫЛА ФОТКА__\n",
    "\n",
    "__RTAB-Map  has  a  variety  of  input  topics  (e.g.,  RGB-D  images,  stereo  images,  odometry,  2D  laser  scan,3D point cloud and user data) that can be used depending on the sensors available.  The minimum topicsthat are required to make thertabmapROS node work are registered RGB-D or calibrated stereo imageswith  odometry,  provided  through  a  topic  or  bytf__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OctoMap is created from the single local occupancy grid in the robot referential.OctoMap does 3D ray tracing and detects empty cells between the camera and occupied cells.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loop closure detection is done using the bag-of-words approach. when  creating  a  new  node,  STM  extracts  visual  features  from  the  RGB  image  and  quantizesthem to an incremental visual word vocabulary.  Features can be any of the types included in OpenCV. only a subset (maximum of “Kp/MaxFeatures”) of the odometry features with highest response are quantized tovisual word vocabulary. The created node is then compared to nodes in WM to detect a loop closure.  When a loop closure hypothesis reaches the fixed threshold “Rtabmap/LoopThr”,a loop closure is detected and transformation is computed using motion estimation approach.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ИНТЕРЕСНО ДЛЯ CARTOHRAPHER__\n",
    "\n",
    "__Depending on the parameters “Grid/FromDepth”, “Grid/3D” and the input topics set, the local occupancygrid is generated differently and the result is either 2D or 3D, as shown in Figure 7.  For example, if parameter“Grid/FromDepth” is false andrtabmapnode is subscribed to a laser scan topic, a local 2D occupancy gridis  created.__ p.14\n",
    "\n",
    "__2D Ray Tracing:  For each ray of the laser rangefinder, a line is traced on the grid to fill empty cellsbetween the sensor and the obstacle hit by the ray.  It is assumed that the rays are parallel to theground.  This approach can generate 2D local occupancy grids very fast and is done by default for2D lidar-based mapping.__\n",
    "\n",
    "and 1 more\n",
    "\n",
    "__Projection:  If “Grid/3D” is false, the 3D ground and obstacle point clouds are projected on groundplane (e.g.,x-yplane).  The voxel grid filter is applied again to merge points projected in the samecell.  2D ray tracing can be done to fill empty space between obstacles and the camera.  If 2D raytracing is not used and if the point cloud does not have any points segmented as ground, no emptycells are set in the occupancy grid between the sensor and the obstacles__\n",
    "\n",
    "\n",
    "__SECTION 5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__KITTI__\n",
    "\n",
    "Metrics ?\n",
    "\n",
    "All  errors  are  computed  with  the  map’s  graph  including  loop closures.\n",
    "\n",
    "_?  Localizationrobustness is not addressed explicitly but in all the results presented, no wrong loop closures were accepted ?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. e.\n",
    "\n",
    "<img src='../media/kitti_ex.png'>\n",
    "<img src='../media/kitti_ex_better.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../media/maps.png'>\n",
    "<img src='../media/desired_submaps.png'>\n",
    "\n",
    "__Theglobal trajectories done during each session are shown in purple and orange, respectively.  Neighbor, loopclosure and proximity links are shown in blue, red and yellow, respectively.  The green path is the groundtruth, which is almost not visible in (b) and (c) as the blue line is superposed.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОПИСАНИЕ СЕНСОРОВ ДЛЯ КАЖДОГО СЛУЧАЯ. ЧТО БЫЛ ЗА РОБОТ\n",
    "\n",
    "ТАБЛИЦА ОШИБОК КИТТИ ДЛЯ РАЗНЫХ ПАРАМЕТРОВ\n",
    "\n",
    "i. e. average transla-tional error metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.5px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
